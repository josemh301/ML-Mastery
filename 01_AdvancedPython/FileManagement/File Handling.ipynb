{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Handling in Python\n",
    "File handling, often referred to as file I/O (input/output), allows us to read from and write to files. In the context of Machine Learning, handling data files efficiently is crucial, as datasets are the backbone of any ML model.\n",
    "\n",
    "### Common File Types in Machine Learning:\n",
    "1. Text Files (.txt): Simple files that contain plain text.\n",
    "1. CSV (Comma-Separated Values) Files (.csv): Used to store tabular data.\n",
    "1. Excel Files (.xls, .xlsx): Spreadsheet files.\n",
    "1. JSON (JavaScript Object Notation) Files (.json): Stores data as text in a human-readable format.\n",
    "1. HDF5 Files: Used for storing large datasets.\n",
    "1. Parquet and Feather Files: Columnar storage file formats optimized for analytics.\n",
    "1. Image Files (.jpg, .png, etc.): For computer vision tasks.\n",
    "1. Pickle Files (.pkl): Python-specific format used to serialize and deserialize Python objects.  \n",
    "\n",
    "#### Basic File Operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading a text file\n",
    "with open('file.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to a text file\n",
    "with open('file.txt', 'w') as file:\n",
    "    file.write('Hello, World!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ClientID', 'ClientName', 'Budget', 'Expenses', 'Revenue', 'Profit', 'FinancialAdvisor']\n",
      "['101', 'Acme Corp', '50000', '30000', '65000', '35000', 'Alice Johnson']\n",
      "['102', 'Beta Inc', '75000', '50000', '90000', '40000', 'Bob Smith']\n",
      "['103', 'Charlie LLC', '60000', '45000', '80000', '35000', 'Carol White']\n",
      "['104', 'Delta Co', '85000', '70000', '110000', '40000', 'Dave Brown']\n",
      "['105', 'Echo Ltd', '95000', '85000', '120000', '35000', 'Eve Green']\n",
      "['106', 'Foxtrot Enterprises', '70000', '65000', '100000', '35000', 'Frank Black']\n",
      "['107', 'Golf Corp', '80000', '75000', '105000', '30000', 'Grace Blue']\n",
      "['108', 'Hotel Inc', '90000', '85000', '115000', '30000', 'Hank Yellow']\n",
      "['109', 'India LLC', '95000', '90000', '125000', '35000', 'Ivy Red']\n",
      "['110', 'Juliet Co', '99000', '94000', '130000', '36000', 'Jack Violet']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Reading a CSV file\n",
    "with open('data.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading an Excel file\n",
    "data = pd.read_excel('data.xlsx')\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FinancialData': [{'ClientID': 101, 'ClientName': 'Acme Corp', 'Budget': 50000, 'Expenses': 30000, 'Revenue': 65000, 'Profit': 35000, 'FinancialAdvisor': 'Alice Johnson'}, {'ClientID': 102, 'ClientName': 'Beta Inc', 'Budget': 75000, 'Expenses': 50000, 'Revenue': 90000, 'Profit': 40000, 'FinancialAdvisor': 'Bob Smith'}, {'ClientID': 103, 'ClientName': 'Charlie LLC', 'Budget': 60000, 'Expenses': 45000, 'Revenue': 80000, 'Profit': 35000, 'FinancialAdvisor': 'Carol White'}, {'ClientID': 104, 'ClientName': 'Delta Co', 'Budget': 85000, 'Expenses': 70000, 'Revenue': 110000, 'Profit': 40000, 'FinancialAdvisor': 'Dave Brown'}, {'ClientID': 105, 'ClientName': 'Echo Ltd', 'Budget': 95000, 'Expenses': 85000, 'Revenue': 120000, 'Profit': 35000, 'FinancialAdvisor': 'Eve Green'}, {'ClientID': 106, 'ClientName': 'Foxtrot Enterprises', 'Budget': 70000, 'Expenses': 65000, 'Revenue': 100000, 'Profit': 35000, 'FinancialAdvisor': 'Frank Black'}, {'ClientID': 107, 'ClientName': 'Golf Corp', 'Budget': 80000, 'Expenses': 75000, 'Revenue': 105000, 'Profit': 30000, 'FinancialAdvisor': 'Grace Blue'}, {'ClientID': 108, 'ClientName': 'Hotel Inc', 'Budget': 90000, 'Expenses': 85000, 'Revenue': 115000, 'Profit': 30000, 'FinancialAdvisor': 'Hank Yellow'}, {'ClientID': 109, 'ClientName': 'India LLC', 'Budget': 95000, 'Expenses': 90000, 'Revenue': 125000, 'Profit': 35000, 'FinancialAdvisor': 'Ivy Red'}, {'ClientID': 110, 'ClientName': 'Juliet Co', 'Budget': 99000, 'Expenses': 94000, 'Revenue': 130000, 'Profit': 36000, 'FinancialAdvisor': 'Jack Violet'}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Reading a JSON file\n",
    "with open('data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Opening an image file\n",
    "img = Image.open('image.jpg')\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Fake financial data\n",
    "financial_data = {\n",
    "    \"FinancialData\": [\n",
    "        {\"ClientID\": 101, \"ClientName\": \"Acme Corp\", \"Budget\": 50000, \"Expenses\": 30000, \"Revenue\": 65000, \"Profit\": 35000, \"FinancialAdvisor\": \"Alice Johnson\"},\n",
    "        {\"ClientID\": 102, \"ClientName\": \"Beta Inc\", \"Budget\": 75000, \"Expenses\": 50000, \"Revenue\": 90000, \"Profit\": 40000, \"FinancialAdvisor\": \"Bob Smith\"},\n",
    "        # ... (you can add more fake data entries as needed) ...\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Saving the data to a .pkl file\n",
    "with open('fake_financial_data.pkl', 'wb') as file:\n",
    "    pickle.dump(financial_data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fake_financial_data.pkl', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "print(loaded_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File handling is essential for managing datasets in Machine Learning. Whether you're preprocessing data, storing intermediate results, or logging model metrics, understanding how to efficiently read from and write to files is crucial. Python, with its rich standard library and third-party packages, offers robust tools for file I/O operations, making it easier to handle various file formats commonly used in ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
