{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Loss: Gradient Descent\n",
    "\n",
    "[Source](https://developers.google.com/machine-learning/crash-course/descending-into-ml/video-lecture)\n",
    "\n",
    "In Machine Learning, we teach models to get better at making predictions. Think of a model like a person throwing darts at a dartboard. At first, the throws (or predictions) are inaccurate and miss the target. We want our model to hit the bullseye, or make accurate predictions.\n",
    "\n",
    "### How it Works\n",
    "1. **Start Somewhere:**\n",
    "   Imagine you are blindfolded and throwing darts. You start by throwing a dart anywhere on the board.\n",
    "\n",
    "2. **Get Feedback:**\n",
    "   Someone tells you how far and in which direction you are from the bullseye. In machine learning, this feedback is called the \"gradient,\" and it tells the model how off its predictions are.\n",
    "\n",
    "3. **Adjust Your Throw:**\n",
    "   Based on the feedback, you adjust your next throw to be closer to the bullseye. In machine learning, we adjust the model's \"parameters\" to make better predictions. How much you adjust is like choosing how big of a step to take, and it’s called the \"learning rate.\"\n",
    "\n",
    "4. **Repeat:**\n",
    "   You keep adjusting your throws based on feedback until you hit the bullseye or get very close to it. In machine learning, we keep adjusting the model until it makes good predictions.\n",
    "\n",
    "### Learning Rate\n",
    "The learning rate is like deciding how big of a step to take when adjusting. If you take too big of a step, you might overshoot and miss the target. If you take tiny steps, it might take a very long time to reach the target, or you might get stuck and never reach it.\n",
    "\n",
    "### Types of Gradient Descent\n",
    "- **Batch Gradient Descent:**\n",
    "   Like considering advice from all your friends at once when adjusting your throw.\n",
    "   \n",
    "- **Stochastic Gradient Descent (SGD):**\n",
    "   Like considering advice from only one friend at a time. It’s usually quicker but can be less accurate.\n",
    "   \n",
    "- **Mini-Batch Gradient Descent:**\n",
    "   Like considering advice from a small group of friends. It’s a middle ground between considering everyone and just one friend.\n",
    "\n",
    "### Simplified Explanation\n",
    "Gradient Descent is like learning to throw darts blindfolded. You start somewhere, get feedback on how off you are, adjust your throw based on the feedback, and repeat until you are close to the bullseye. How you adjust and whose advice you consider (yours alone, everyone’s, or a small group's) can vary, affecting how quickly and accurately you learn to hit the target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note. Add example following day"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
